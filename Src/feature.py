# -*- coding: utf-8 -*-
"""Feature.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1biPaUlHZmuIDUtU70jWYH7bo5qkECunJ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import sys
import joblib
from wordcloud import WordCloud

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.dummy import DummyClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Dense, Embedding, GlobalAveragePooling1D, Dropout

#@title Feature
def get_tfidf_features(train_text, test_text):

    print("\n Feature Engineering: TF-IDF")
    tfidf = TfidfVectorizer(max_features=5000, stop_words='english')
    X_train = tfidf.fit_transform(train_text)
    X_test = tfidf.transform(test_text)
    print(f"TF-IDF Shape: {X_train.shape}")
    return X_train, X_test, tfidf

def get_sequence_features(train_text, test_text, vocab_size=10000, max_len=200):
    print("\n--- [3B] Feature Engineering: Tokenization ---")
    tokenizer = Tokenizer(num_words=vocab_size, oov_token="<OOV>")
    tokenizer.fit_on_texts(train_text)

    train_seq = tokenizer.texts_to_sequences(train_text)
    test_seq = tokenizer.texts_to_sequences(test_text)

    X_train_pad = pad_sequences(train_seq, maxlen=max_len, padding='post', truncating='post')
    X_test_pad = pad_sequences(test_seq, maxlen=max_len, padding='post', truncating='post')
    print(f"Sequence Shape: {X_train_pad.shape}")
    return X_train_pad, X_test_pad