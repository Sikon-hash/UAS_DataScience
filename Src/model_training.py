# -*- coding: utf-8 -*-
"""Model training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1biPaUlHZmuIDUtU70jWYH7bo5qkECunJ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import sys
import joblib
from wordcloud import WordCloud

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.dummy import DummyClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Dense, Embedding, GlobalAveragePooling1D, Dropout

#@title Modeling Training
def train_models(X_train_tfidf, X_test_tfidf, X_train_seq, X_test_seq, y_train, y_test, classes, vocab_size, max_len):
    model_scores = {}

    # Baseline
    print("\n=== Model 1: Baseline (Dummy) ===")
    base_model = DummyClassifier(strategy='most_frequent')
    base_model.fit(X_train_tfidf, y_train)
    y_pred_base = base_model.predict(X_test_tfidf)
    acc_base = accuracy_score(y_test, y_pred_base)
    model_scores['Baseline'] = acc_base
    print(classification_report(y_test, y_pred_base, target_names=classes, zero_division=0))

    # Random Forest
    print("\n=== Model 2: Random Forest ===")
    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
    rf_model.fit(X_train_tfidf, y_train)
    y_pred_rf = rf_model.predict(X_test_tfidf)
    acc_rf = accuracy_score(y_test, y_pred_rf)
    model_scores['Random Forest'] = acc_rf
    print(classification_report(y_test, y_pred_rf, target_names=classes, zero_division=0))

    # Deep Learning
    print("\n=== Model 3: Deep Learning (TensorFlow) ===")
    num_classes = len(classes)

    model = Sequential([
        Input(shape=(max_len,)),
        Embedding(input_dim=vocab_size, output_dim=16),
        GlobalAveragePooling1D(),
        Dense(24, activation='relu'),
        Dropout(0.5),
        Dense(num_classes, activation='softmax')
    ])

    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

    history = model.fit(
        X_train_seq, y_train,
        epochs=15,
        validation_data=(X_test_seq, y_test),
        verbose=1
    )

    # Evaluasi DL
    print("\nEvaluasi Akhir Deep Learning:")
    y_pred_probs = model.predict(X_test_seq)
    y_pred_dl = np.argmax(y_pred_probs, axis=1)
    acc_dl = accuracy_score(y_test, y_pred_dl)
    model_scores['Deep Learning'] = acc_dl
    print(classification_report(y_test, y_pred_dl, target_names=classes, zero_division=0))

    return history, model_scores, base_model, rf_model, model